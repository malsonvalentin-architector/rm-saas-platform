"""
ProMonitor V2 - AI Assistant Backend
GPT-4 powered monitoring assistant with smart building analysis
"""

import json
from datetime import datetime, timedelta

# Conditional OpenAI import
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    openai = None
    OPENAI_AVAILABLE = False
from django.conf import settings
from django.utils import timezone
from data.models import Obj as Building, System as SensorSystem, Atributes as Sensor, Data as SensorReading, AlertEvent as Alert
from .utils import get_building_status, get_company_overview, calculate_sensor_health


class ProMonitorAIAssistant:
    """
    AI Assistant for ProMonitor - GPT-4 powered building monitoring expert
    """
    
    def __init__(self, user):
        self.user = user
        self.company = user.company
        
        # Initialize OpenAI (will use API key when provided)
        # For now, we'll create intelligent responses without actual GPT-4
        self.gpt_available = (
            OPENAI_AVAILABLE and 
            hasattr(settings, 'OPENAI_API_KEY') and 
            settings.OPENAI_API_KEY
        )
        
        if self.gpt_available and openai:
            openai.api_key = settings.OPENAI_API_KEY
    
    def process_message(self, message, context=None, history=None):
        """
        Process user message and generate AI response
        """
        # Analyze message intent
        intent = self.analyze_intent(message)
        
        # Get relevant data based on intent
        data = self.gather_relevant_data(intent, context)
        
        # Generate response
        if self.gpt_available:
            response = self.generate_gpt_response(message, data, history)
        else:
            response = self.generate_smart_response(message, intent, data)
        
        return {
            'message': response['text'],
            'timestamp': datetime.now().isoformat(),
            'confidence': response.get('confidence', 0.9),
            'actions': response.get('actions', []),
            'intent': intent,
            'data_used': response.get('data_sources', [])
        }
    
    def analyze_intent(self, message):
        """
        Analyze user message to determine intent
        """
        message_lower = message.lower()
        
        # Intent patterns
        intents = {
            'status_check': [
                '—Å—Ç–∞—Ç—É—Å', '—Å–æ—Å—Ç–æ—è–Ω–∏–µ', '—Ä–∞–±–æ—Ç–∞–µ—Ç', '–∑–¥–æ—Ä–æ–≤—å–µ —Å–∏—Å—Ç–µ–º—ã', 'overview',
                'show status', 'system health', '–∫–∞–∫ –¥–µ–ª–∞'
            ],
            'alerts_query': [
                '–∞–ª–µ—Ä—Ç', '—Ç—Ä–µ–≤–æ–≥', '–ø—Ä–æ–±–ª–µ–º', '–∫—Ä–∏—Ç–∏—á', 'warning', 'alert',
                '—á—Ç–æ –Ω–µ —Ç–∞–∫', '–æ—à–∏–±–∫–∏', '—Å–±–æ–∏'
            ],
            'temperature_analysis': [
                '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä', 'temperature', '—Ç–µ–ø–ª–æ', '—Ö–æ–ª–æ–¥–Ω–æ', '–≥—Ä–∞–¥—É—Å',
                'temp', '–∫–ª–∏–º–∞—Ç'
            ],
            'humidity_analysis': [
                '–≤–ª–∞–∂–Ω–æ—Å—Ç—å', 'humidity', '—Å—É—Ö–æ', '–≤–ª–∞–≥–∞'
            ],
            'building_specific': [
                '–∑–¥–∞–Ω–∏–µ', '–æ—Ñ–∏—Å', '—Å–∫–ª–∞–¥', 'building', '–ø–æ–º–µ—â–µ–Ω–∏–µ'
            ],
            'sensor_query': [
                '–¥–∞—Ç—á–∏–∫', 'sensor', '–ø–æ–∫–∞–∑–∞–Ω–∏—è', '–∏–∑–º–µ—Ä–µ–Ω–∏—è', '–¥–∞–Ω–Ω—ã–µ'
            ],
            'analytics_request': [
                '–∞–Ω–∞–ª–∏–∑', 'analytics', '—Ç—Ä–µ–Ω–¥', '–≥—Ä–∞—Ñ–∏–∫', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞',
                '–∑–∞ –ø–µ—Ä–∏–æ–¥', '–¥–∏–Ω–∞–º–∏–∫–∞'
            ],
            'recommendations': [
                '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏', '—Å–æ–≤–µ—Ç—ã', '–∫–∞–∫ —É–ª—É—á—à–∏—Ç—å', '–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è',
                '—ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ', 'recommendations'
            ],
            'help_request': [
                '–ø–æ–º–æ—â—å', 'help', '—á—Ç–æ –º–æ–∂–µ—à—å', '–∫–æ–º–∞–Ω–¥—ã', '–∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è'
            ]
        }
        
        # Score each intent
        intent_scores = {}
        for intent, keywords in intents.items():
            score = sum(1 for keyword in keywords if keyword in message_lower)
            if score > 0:
                intent_scores[intent] = score
        
        # Return highest scoring intent or 'general' if none found
        if intent_scores:
            return max(intent_scores.items(), key=lambda x: x[1])[0]
        else:
            return 'general'
    
    def gather_relevant_data(self, intent, context=None):
        """
        Gather relevant data based on intent and context
        """
        data = {
            'company_overview': get_company_overview(self.company),
            'timestamp': timezone.now()
        }
        
        # Get buildings data
        buildings = Building.objects.filter(company=self.company)
        data['buildings'] = []
        
        for building in buildings:
            building_data = {
                'id': building.id,
                'name': building.obj,
                'status': get_building_status(building),
                'sensors': [],
                'recent_alerts': []
            }
            
            # Get sensors for this building
            sensors = Sensor.objects.filter(sys__obj=building)[:10]  # Limit for performance
            for sensor in sensors:
                latest_reading = SensorReading.objects.filter(
                    name=sensor
                ).order_by('-date').first()
                
                building_data['sensors'].append({
                    'name': sensor.name,
                    'value': latest_reading.value if latest_reading else None,
                    'unit': sensor.uom,
                    'status': calculate_sensor_health(sensor),
                    'last_update': latest_reading.date if latest_reading else None
                })
            
            # Get recent alerts for this building
            recent_alerts = Alert.objects.filter(
                rule__attribute__sys__obj=building,
                triggered_at__gte=timezone.now() - timedelta(hours=24)
            ).order_by('-triggered_at')[:5]
            
            for alert in recent_alerts:
                building_data['recent_alerts'].append({
                    'status': alert.status,
                    'triggered_at': alert.triggered_at,
                    'value': alert.value,
                    'sensor_name': alert.rule.attribute.name
                })
            
            data['buildings'].append(building_data)
        
        # Intent-specific data gathering
        if intent == 'temperature_analysis':
            data['temperature_data'] = self.get_temperature_analysis()
        elif intent == 'humidity_analysis':
            data['humidity_data'] = self.get_humidity_analysis()
        elif intent == 'alerts_query':
            data['detailed_alerts'] = self.get_detailed_alerts()
        elif intent == 'analytics_request':
            data['analytics'] = self.get_analytics_data()
        
        return data
    
    def get_temperature_analysis(self):
        """Get temperature-specific analysis"""
        now = timezone.now()
        last_24h = now - timedelta(hours=24)
        
        temp_readings = SensorReading.objects.filter(
            name__sys__obj__company=self.company,
            name__name__icontains='temperature',
            date__gte=last_24h
        ).order_by('-date')[:100]
        
        if not temp_readings:
            return None
        
        temps = [float(r.value) for r in temp_readings]
        return {
            'current_avg': sum(temps) / len(temps),
            'min_temp': min(temps),
            'max_temp': max(temps),
            'readings_count': len(temps),
            'trend': 'stable'  # TODO: Calculate actual trend
        }
    
    def get_humidity_analysis(self):
        """Get humidity-specific analysis"""
        now = timezone.now()
        last_24h = now - timedelta(hours=24)
        
        humidity_readings = SensorReading.objects.filter(
            name__sys__obj__company=self.company,
            name__name__icontains='humidity',
            date__gte=last_24h
        ).order_by('-date')[:100]
        
        if not humidity_readings:
            return None
        
        humidity_values = [float(r.value) for r in humidity_readings]
        return {
            'current_avg': sum(humidity_values) / len(humidity_values),
            'min_humidity': min(humidity_values),
            'max_humidity': max(humidity_values),
            'readings_count': len(humidity_values)
        }
    
    def get_detailed_alerts(self):
        """Get detailed alerts information"""
        now = timezone.now()
        last_24h = now - timedelta(hours=24)
        
        alerts = Alert.objects.filter(
            rule__attribute__sys__obj__company=self.company,
            triggered_at__gte=last_24h
        ).select_related(
            'rule', 'rule__attribute', 'rule__attribute__sys', 'rule__attribute__sys__obj'
        ).order_by('-triggered_at')
        
        alert_data = {
            'total_count': alerts.count(),
            'active_count': alerts.filter(status='active').count(),
            'resolved_count': alerts.filter(status='resolved').count(),
            'by_building': {},
            'recent_alerts': []
        }
        
        # Group by building
        for alert in alerts[:20]:  # Limit for performance
            building_name = alert.rule.attribute.sys.obj.obj
            if building_name not in alert_data['by_building']:
                alert_data['by_building'][building_name] = 0
            alert_data['by_building'][building_name] += 1
            
            alert_data['recent_alerts'].append({
                'building': building_name,
                'sensor': alert.rule.attribute.name,
                'status': alert.status,
                'value': alert.value,
                'triggered_at': alert.triggered_at.strftime('%H:%M')
            })
        
        return alert_data
    
    def get_analytics_data(self):
        """Get analytics data for the last 24 hours"""
        now = timezone.now()
        last_24h = now - timedelta(hours=24)
        
        # Reading counts by hour
        readings_by_hour = {}
        for hour in range(24):
            hour_start = now - timedelta(hours=hour+1)
            hour_end = now - timedelta(hours=hour)
            
            count = SensorReading.objects.filter(
                name__sys__obj__company=self.company,
                date__gte=hour_start,
                date__lt=hour_end
            ).count()
            
            readings_by_hour[f"{hour_start.hour:02d}:00"] = count
        
        return {
            'readings_by_hour': readings_by_hour,
            'total_readings_24h': sum(readings_by_hour.values()),
            'active_sensors': Sensor.objects.filter(sys__obj__company=self.company).count(),
            'active_buildings': Building.objects.filter(company=self.company).count()
        }
    
    def generate_smart_response(self, message, intent, data):
        """
        Generate intelligent response without GPT-4 (fallback mode)
        """
        responses = {
            'status_check': self.generate_status_response(data),
            'alerts_query': self.generate_alerts_response(data),
            'temperature_analysis': self.generate_temperature_response(data),
            'humidity_analysis': self.generate_humidity_response(data),
            'building_specific': self.generate_building_response(data),
            'sensor_query': self.generate_sensor_response(data),
            'analytics_request': self.generate_analytics_response(data),
            'recommendations': self.generate_recommendations_response(data),
            'help_request': self.generate_help_response()
        }
        
        if intent in responses:
            return responses[intent]
        else:
            return self.generate_general_response(data)
    
    def generate_status_response(self, data):
        """Generate system status response"""
        overview = data['company_overview']
        buildings = data['buildings']
        
        status_counts = overview['building_statuses']
        total_buildings = overview['total_buildings']
        
        response = f"üìä **–û–±—â–∏–π —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:**\n\n"
        response += f"üè¢ **–ó–¥–∞–Ω–∏–π:** {total_buildings}\n"
        response += f"üì° **–î–∞—Ç—á–∏–∫–æ–≤:** {overview['total_sensors']}\n"
        response += f"‚ö° **–ê–∫—Ç–∏–≤–Ω—ã—Ö –∞–ª–µ—Ä—Ç–æ–≤:** {overview['active_alerts']}\n"
        response += f"üìà **–ê–ø—Ç–∞–π–º —Å–∏—Å—Ç–µ–º—ã:** {overview['system_uptime']:.1f}%\n\n"
        
        response += "**–°—Ç–∞—Ç—É—Å –∑–¥–∞–Ω–∏–π:**\n"
        if status_counts['healthy'] > 0:
            response += f"‚úÖ –ù–æ—Ä–º–∞: {status_counts['healthy']}\n"
        if status_counts['warning'] > 0:
            response += f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {status_counts['warning']}\n"
        if status_counts['critical'] > 0:
            response += f"üö® –ö—Ä–∏—Ç–∏—á–Ω—ã–µ: {status_counts['critical']}\n"
        if status_counts['offline'] > 0:
            response += f"üì¥ –û—Ñ–ª–∞–π–Ω: {status_counts['offline']}\n"
        
        if overview['avg_temperature']:
            response += f"\nüå°Ô∏è **–°—Ä–µ–¥–Ω—è—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:** {overview['avg_temperature']}¬∞C"
        if overview['avg_humidity']:
            response += f"\nüíß **–°—Ä–µ–¥–Ω—è—è –≤–ª–∞–∂–Ω–æ—Å—Ç—å:** {overview['avg_humidity']}%"
        
        actions = []
        if status_counts['critical'] > 0:
            actions.append({
                'type': 'highlight_critical',
                'message': '–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∑–¥–∞–Ω–∏—è'
            })
        
        return {
            'text': response,
            'confidence': 0.95,
            'actions': actions,
            'data_sources': ['company_overview', 'buildings']
        }
    
    def generate_alerts_response(self, data):
        """Generate alerts analysis response"""
        if 'detailed_alerts' not in data:
            return {
                'text': "–°–æ–±–∏—Ä–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–ª–µ—Ä—Ç–∞—Ö...",
                'confidence': 0.7
            }
        
        alerts = data['detailed_alerts']
        
        if alerts['total_count'] == 0:
            return {
                'text': "üéâ **–û—Ç–ª–∏—á–Ω–æ! –ê–∫—Ç–∏–≤–Ω—ã—Ö –∞–ª–µ—Ä—Ç–æ–≤ –Ω–µ—Ç.**\n\n–í–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ. –í—Å–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤ –Ω–æ—Ä–º–µ.",
                'confidence': 0.9
            }
        
        response = f"üö® **–ê–Ω–∞–ª–∏–∑ –∞–ª–µ—Ä—Ç–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞:**\n\n"
        response += f"üìä **–í—Å–µ–≥–æ:** {alerts['total_count']}\n"
        response += f"üî¥ **–ê–∫—Ç–∏–≤–Ω—ã—Ö:** {alerts['active_count']}\n"
        response += f"‚úÖ **–†–µ—à–µ–Ω–æ:** {alerts['resolved_count']}\n\n"
        
        if alerts['by_building']:
            response += "**–ü–æ –∑–¥–∞–Ω–∏—è–º:**\n"
            for building, count in sorted(alerts['by_building'].items(), key=lambda x: x[1], reverse=True):
                response += f"‚Ä¢ {building}: {count} –∞–ª–µ—Ä—Ç–æ–≤\n"
        
        if alerts['recent_alerts']:
            response += "\n**–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∞–ª–µ—Ä—Ç—ã:**\n"
            for alert in alerts['recent_alerts'][:5]:
                status_icon = "üî¥" if alert['status'] == 'active' else "üü°" if alert['status'] == 'acknowledged' else "‚úÖ"
                response += f"{status_icon} {alert['building']} - {alert['sensor']} ({alert['triggered_at']})\n"
        
        return {
            'text': response,
            'confidence': 0.9,
            'data_sources': ['detailed_alerts']
        }
    
    def generate_temperature_response(self, data):
        """Generate temperature analysis response"""
        if 'temperature_data' not in data or not data['temperature_data']:
            return {
                'text': "üå°Ô∏è –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –¥–∞–Ω–Ω—ã–µ –æ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –¥–∞—Ç—á–∏–∫–æ–≤ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã.",
                'confidence': 0.8
            }
        
        temp_data = data['temperature_data']
        
        response = f"üå°Ô∏è **–ê–Ω–∞–ª–∏–∑ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞:**\n\n"
        response += f"üìä **–°—Ä–µ–¥–Ω—è—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:** {temp_data['current_avg']:.1f}¬∞C\n"
        response += f"ü•∂ **–ú–∏–Ω–∏–º—É–º:** {temp_data['min_temp']:.1f}¬∞C\n"
        response += f"ü•µ **–ú–∞–∫—Å–∏–º—É–º:** {temp_data['max_temp']:.1f}¬∞C\n"
        response += f"üìà **–ü–æ–∫–∞–∑–∞–Ω–∏–π:** {temp_data['readings_count']}\n\n"
        
        # Analysis
        avg_temp = temp_data['current_avg']
        if avg_temp < 18:
            response += "‚ùÑÔ∏è **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–∏–∂–µ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–π. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –æ—Ç–æ–ø–ª–µ–Ω–∏—è."
        elif avg_temp > 26:
            response += "üî• **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤—ã—à–µ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–π. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è."
        else:
            response += "‚úÖ **–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ** (18-26¬∞C)"
        
        return {
            'text': response,
            'confidence': 0.9,
            'data_sources': ['temperature_data']
        }
    
    def generate_humidity_response(self, data):
        """Generate humidity analysis response"""
        if 'humidity_data' not in data or not data['humidity_data']:
            return {
                'text': "üíß –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –¥–∞–Ω–Ω—ã–µ –æ –≤–ª–∞–∂–Ω–æ—Å—Ç–∏ —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –¥–∞—Ç—á–∏–∫–æ–≤ –≤–ª–∞–∂–Ω–æ—Å—Ç–∏.",
                'confidence': 0.8
            }
        
        humidity_data = data['humidity_data']
        
        response = f"üíß **–ê–Ω–∞–ª–∏–∑ –≤–ª–∞–∂–Ω–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞:**\n\n"
        response += f"üìä **–°—Ä–µ–¥–Ω—è—è –≤–ª–∞–∂–Ω–æ—Å—Ç—å:** {humidity_data['current_avg']:.1f}%\n"
        response += f"üìâ **–ú–∏–Ω–∏–º—É–º:** {humidity_data['min_humidity']:.1f}%\n"
        response += f"üìà **–ú–∞–∫—Å–∏–º—É–º:** {humidity_data['max_humidity']:.1f}%\n"
        response += f"üìä **–ü–æ–∫–∞–∑–∞–Ω–∏–π:** {humidity_data['readings_count']}\n\n"
        
        # Analysis
        avg_humidity = humidity_data['current_avg']
        if avg_humidity < 30:
            response += "üèúÔ∏è **–í–Ω–∏–º–∞–Ω–∏–µ:** –í–æ–∑–¥—É—Ö —Å–ª–∏—à–∫–æ–º —Å—É—Ö–æ–π. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–ª–∞–∂–Ω–µ–Ω–∏–µ."
        elif avg_humidity > 70:
            response += "üåä **–í–Ω–∏–º–∞–Ω–∏–µ:** –í–æ–∑–¥—É—Ö —Å–ª–∏—à–∫–æ–º –≤–ª–∞–∂–Ω—ã–π. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å—É—à–µ–Ω–∏–µ."
        else:
            response += "‚úÖ **–í–ª–∞–∂–Ω–æ—Å—Ç—å –≤ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ** (30-70%)"
        
        return {
            'text': response,
            'confidence': 0.9,
            'data_sources': ['humidity_data']
        }
    
    def generate_help_response(self):
        """Generate help response"""
        response = """ü§ñ **–Ø –≤–∞—à AI –ø–æ–º–æ—â–Ω–∏–∫ ProMonitor! –í–æ—Ç —á—Ç–æ —è —É–º–µ—é:**

**üìä –ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã:**
‚Ä¢ "–ü–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∑–¥–∞–Ω–∏–π"
‚Ä¢ "–ï—Å—Ç—å –ª–∏ –ø—Ä–æ–±–ª–µ–º—ã –≤ —Å–∏—Å—Ç–µ–º–µ?"
‚Ä¢ "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–∏—Å—Ç–µ–º–∞?"

**üö® –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–ª–µ—Ä—Ç–∞–º–∏:**
‚Ä¢ "–ü–æ–∫–∞–∂–∏ –≤—Å–µ –∞–ª–µ—Ä—Ç—ã"
‚Ä¢ "–ï—Å—Ç—å –ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã?"
‚Ä¢ "–ß—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è?"

**üå°Ô∏è –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö:**
‚Ä¢ "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É"
‚Ä¢ "–ü—Ä–æ–≤–µ—Ä—å –≤–ª–∞–∂–Ω–æ—Å—Ç—å"
‚Ä¢ "–ü–æ–∫–∞–∂–∏ –¥–∞–Ω–Ω—ã–µ –¥–∞—Ç—á–∏–∫–æ–≤"

**üìà –ê–Ω–∞–ª–∏—Ç–∏–∫–∞:**
‚Ä¢ "–ü–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ —Å—É—Ç–∫–∏"
‚Ä¢ "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–µ–Ω–¥—ã"
‚Ä¢ "–ö–∞–∫ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏?"

**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
‚Ä¢ "–î–∞–π —Å–æ–≤–µ—Ç—ã –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"
‚Ä¢ "–ö–∞–∫ —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å —ç–Ω–µ—Ä–≥–∏—é?"
‚Ä¢ "–ß—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å?"

–ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–º! üòä"""
        
        return {
            'text': response,
            'confidence': 1.0
        }
    
    def generate_general_response(self, data):
        """Generate general response"""
        return {
            'text': "–ü–æ–Ω—è–ª –≤–∞—à –≤–æ–ø—Ä–æ—Å! –Ø –º–æ–≥—É –ø–æ–º–æ—á—å —Å –∞–Ω–∞–ª–∏–∑–æ–º –∑–¥–∞–Ω–∏–π, –¥–∞—Ç—á–∏–∫–æ–≤ –∏ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞. –ß—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?",
            'confidence': 0.6
        }
    
    def generate_gpt_response(self, message, data, history):
        """
        Generate response using GPT-4 (when API key is available)
        """
        # TODO: Implement actual GPT-4 integration
        # This would be implemented when OpenAI API key is provided
        system_prompt = self.build_system_prompt(data)
        
        # For now, fallback to smart response
        return self.generate_smart_response(message, self.analyze_intent(message), data)
    
    def build_system_prompt(self, data):
        """
        Build system prompt for GPT-4 with current context
        """
        prompt = f"""You are ProMonitor AI Assistant, an expert in building monitoring and IoT systems.

Current company data:
- Total buildings: {data['company_overview']['total_buildings']}
- Total sensors: {data['company_overview']['total_sensors']}
- Active alerts: {data['company_overview']['active_alerts']}
- System uptime: {data['company_overview']['system_uptime']:.1f}%

Respond in Russian, be helpful and professional. Provide actionable insights.
Use emojis appropriately. Format important information with **bold** text.
"""
        return prompt